{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f959b450",
   "metadata": {},
   "source": [
    "# Experiment README"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd28658",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Overview of Experiment Architecture](#Overview-of-Experiment-Architecture)\n",
    "* [Experiment Workflow](#Experiment-Workflow)\n",
    "    * [Modifying State Variables](#Modifying-State-Variables)\n",
    "    * [Modifying System Parameters](#Modifying-System-Parameters)\n",
    "    * [Executing Experiments](#Executing-Experiments)\n",
    "    * [Post-processing and Analysing Results](#Post-processing-and-Analysing-Results)\n",
    "    * [Visualizing Results](#Visualizing-Results)\n",
    "* [Creating New, Customized Experiment Notebooks](#Creating-New,-Customized-Experiment-Notebooks)\n",
    "    * Step 1: Select an experiment template\n",
    "    * Step 2: Create a new notebook\n",
    "    * Step 3: Customize the experiment\n",
    "    * Step 4: Execute the experiment\n",
    "* [Advanced Experiment-configuration & Simulation Techniques](#Advanced-Experiment-configuration-&-Simulation-Techniques)\n",
    "    * [Setting Simulation Timesteps and Unit of Time `dt`](#Setting-Simulation-Timesteps-and-Unit-of-Time-dt)\n",
    "    * [Changing the Ethereum Network Upgrade Stage](#Changing-the-Ethereum-Network-Upgrade-Stage)\n",
    "    * [Performing Large-scale Experiments](#Performing-Large-scale-Experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335577a",
   "metadata": {},
   "source": [
    "# Overview of Experiment Architecture\n",
    "\n",
    "The experiment architecture is composed of the following four elements – the **model**, **default experiment**, **experiment templates**, and **experiment notebooks**:\n",
    "\n",
    "1. The **model** is initialized with a default Initial State and set of System Parameters defined in the `model` module.\n",
    "2. The **default experiment** – in the `experiments.default_experiment` module – is an experiment composed of a single simulation that uses the default cadCAD **model** Initial State and System Parameters. Additional default simulation execution settings such as the number of timesteps and runs are also set in the **default experiment**.\n",
    "3. The **experiment templates** – in the `experiments.templates` module – contain pre-configured analyses based on the **default experiment**. Examples include... To be created!\n",
    "4. The **experiment notebooks** perform various scenario analyses by importing existing **experiment templates**, optionally modifying the Initial State and System Parameters within the notebook, and then executing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34345968",
   "metadata": {},
   "source": [
    "# Experiment Workflow\n",
    "\n",
    "If you just want to run (execute) existing experiment notebooks, simply open the respective notebook and execute all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d6ab4",
   "metadata": {},
   "source": [
    "Depending on the chosen template and planned analysis, the required imports might differ slightly from the below standard dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e70b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the setup module:\n",
    "# * sets up the Python path\n",
    "# * runs shared notebook-configuration methods, such as loading IPython modules\n",
    "import setup\n",
    "\n",
    "# External dependencies\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pprint import pprint\n",
    "import importlib as imp\n",
    "\n",
    "# Project dependencies\n",
    "import model.constants as constants\n",
    "from experiments.run import run\n",
    "from experiments.utils import display_code\n",
    "import experiments.visualizations as visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e51bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ab2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time\n",
    "#df_dd = dd.read_parquet('../../data/mock_logreturns.prq')\n",
    "#df_pd = pd.read_parquet('../../data/mock_logreturns.prq')\n",
    "#df_pd = pd.read_csv('../../data/mock_logreturns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344e095",
   "metadata": {},
   "source": [
    "We can then import the default experiment, and create a copy of the simulation object – we create a new copy for each analysis we'd like to perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a789f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments.default_experiment as default_experiment\n",
    "simulation_analysis_1 = copy.deepcopy(default_experiment.experiment.simulations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9460b62",
   "metadata": {},
   "source": [
    "We can use the `display_code` method to see the configuration of the default experiment before making changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_code(default_experiment)  # In this example equivalent to display_code(simulation_analysis_1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc5a65",
   "metadata": {},
   "source": [
    "Alternatively to modifying the default experiment in a notebook as shown in the next section, we can also load predefined experiment templates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eccd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import experiments.templates.monte_carlo_analysis as monte_carlo_analysis\n",
    "#simulation_analysis_2 = copy.deepcopy(monte_carlo_analysis.experiment.simulations[0])\n",
    "#display_code(monte_carlo_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd7d53",
   "metadata": {},
   "source": [
    "## Modifying State Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807d1db",
   "metadata": {},
   "source": [
    "To view what the Initial State (radCAD model-configuration setting `initial_state`) of the State Variables are, and to what value they have been set, we can inspect the dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(simulation_analysis_1.model.initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157826bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_analysis_1.model.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20397e",
   "metadata": {},
   "source": [
    "To modify the value of **State Variables** for a specific analysis, you need to select the relevant simulation and update the chosen model Initial State. For example, updating the `floating_supply` Initial State to `100e6` CELO and `123e5` cUSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_analysis_1.model.initial_state.update({\n",
    "    'reserve_balance': {\n",
    "        'celo': 120.0e6,\n",
    "        'cusd': 0.0},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2cee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(simulation_analysis_1.model.initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb589e5",
   "metadata": {},
   "source": [
    "## Modifying System Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcf7ed",
   "metadata": {},
   "source": [
    "To view what the System Parameters (radCAD model configuration setting `params`) are, and to what value they have been set, we can inspect the dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdf992",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(simulation_analysis_1.model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7471a5ed",
   "metadata": {},
   "source": [
    "To modify the value of **System Parameters** for a specific analysis, you need to select the relevant simulation, and update the chosen model System Parameter (which is a list of values). For example, updating the `reserve_fraction` System Parameter to a sweep of two values, `0.001` and `0.01`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_analysis_1.model.params.update({\n",
    "    \"reserve_fraction\": [0.001, 0.01],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de531fb7",
   "metadata": {},
   "source": [
    "## Executing Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69b0e8",
   "metadata": {},
   "source": [
    "We can now execute our custom analysis and retrieve the post-processed Pandas DataFrame using the `run(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125f40a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df, exceptions = run(simulation_analysis_1)\n",
    "#%lprun -T lprof0 -f mp.p_market_price run(simulation_analysis_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08319ab",
   "metadata": {},
   "source": [
    "## Post-processing and Analysing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf691aa9",
   "metadata": {},
   "source": [
    "We can see that we had no exceptions for the single simulation we executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820c404-e38a-4803-a881-3a2c606b8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['subset']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453b62f-3960-4ab3-aaea-e7b1a4eb7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['subset']==0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions[0]['exception'] == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7756c",
   "metadata": {},
   "source": [
    "We can simply display the Pandas DataFrame to inspect the results. This DataFrame already has some default post-processing applied (see [experiments/post_processing.py](../post_processing.py)). For example, parameters that change in the parameter grid (if there are any) are attached as columns to the end of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b11a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which reserve_fraction values were used in the grid\n",
    "df.groupby('subset')['reserve_fraction'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647375d-7516-4e26-9dd7-eee458d3aab7",
   "metadata": {},
   "source": [
    "We can also use Pandas for numerical analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52f2be-059b-4762-b0e2-a6228d7efdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum mento_rate for each subset: in this example each reserve_fraction value used in the grid.\n",
    "df.groupby('subset')['oracle_rate'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2e7ef",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac53e3b",
   "metadata": {},
   "source": [
    "Once we have the results post-processed and in a Pandas DataFrame, we can use Plotly for plotting our results (here two subsets because of the `reserve_fraction` parameter sweep introduced above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mento_rate for each subset (each parameter grid combination) directly from the df (not preferred)\n",
    "visualizations.plot_oracle_rate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d722f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['subset']==0) & (df['run']==1)].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28fb681",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cc61b-001e-4342-b4b3-b071a59c08be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Or use a respective visualizations predefined in the visualizations module (preferred)\n",
    "visualizations.plot_celo_market_price(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_reserve_balance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_cusd_market_price(df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36c3e847213eb5698cc66aeaad5916352a550e6fce59fcba6a957699abbd22fe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "mento2-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
